{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patch_responses.pickle', 'rb') as handle:\n",
    "    \n",
    "    data = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with data from PaStA \n",
    "The \"pasta aggregate\" script aggregates/extracts variousinformation from the mbox-result of PaStA.\n",
    "The responses option extracts and dumps the data for mbox-clusters with patches and all associated\n",
    "emails and commits as a pickled dictionary. These can be further\n",
    "used for input to various analyses on code review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing and exploration\n",
    "We explore some numbers on the input data, like patch count, commit counts, data types etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.patch_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null/NaN patch_ids\n",
    "response_df.fillna({'patch_id':'_'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df['upstream'] = response_df['upstream'].map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.index.name = \"idx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.set_index(['cluster_id', 'patch_id'], append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalize responses\n",
    "The responses column is a dict type with different attributes like mesg_id, parent (parent thread'd mesg id), and the actual message (bytestring) itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_responses = pd.melt(response_df.responses.apply(pd.Series).reset_index(), \n",
    "            id_vars=['idx', 'cluster_id', 'patch_id'],\n",
    "            value_name='responses').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_responses.drop('variable', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library is a wrapper around json_normalize. Due to NaNs in the columns (no responses for some patches). \n",
    "# Ideally one could also use json_normalize, but due to NaNs it would't be straightforward.\n",
    "# In principle we could directly use the flat_table on the list of dicts instead of the melt step above, \n",
    "# but that somehow did not work\n",
    "import flat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_responses = flat_table.normalize(df_melt_responses, expand_dicts=True, expand_lists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_responses.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_responses.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_responses.to_csv(\"df_with_responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_responses = pd.read_csv(\"df_with_responses.csv\", index_col=['idx', 'cluster_id', 'patch_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalize upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream = pd.melt(response_df.upstream.apply(pd.Series).reset_index(),\n",
    "             id_vars=['idx', 'cluster_id', 'patch_id'],\n",
    "             value_name='upstream').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream.drop('variable', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream['upstream'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_upstream.to_csv(\"df_with_upstream.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.multiprocessing\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = dd.read_csv(\"df_with_responses.csv\", blocksize=1e9, dtype={\"cluster_id \": \"int32\", \"patch_id \": \"category\", \\\n",
    "                                                                 \"responses.resp_msg_id\": \"category\", \\\n",
    "                                                                 \"responses.parent\": \"category\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = dd1.set_index(['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dd.read_csv(\"df_with_upstream.csv\", blocksize=1e9, dtype={\"cluster_id \": \"int32\", \"patch_id \": \"category\", \\\n",
    "                                                               \"upstream\": \"category\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dd2.set_index(['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dask_final = dd.merge(dd1, dd2, left_index=True, right_index=True, how='left') \\\n",
    ".drop(['patch_id_y', 'cluster_id_y'], axis=1) \\\n",
    ".reset_index(drop=True) \\\n",
    ".rename(columns={\"cluster_id_x\": \"cluster_id\", \"patch_id_x\": \"patch_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the dataframe (otherwise the computation is lazy)\n",
    "df_dask_final.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be executed directly, instead of compute above to save the frame as a single file\n",
    "df_dask_final.to_csv(\"df_dask_final.csv\", single_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_dask_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary if reading the final dataframe from disk. Reading with Dask gives \n",
    "# the advantage of using the resources better (blocksize parameter), dtypes are tuned to reduce memory usage.\n",
    "final = dd.read_csv(\"df_dask_final.csv\", blocksize=50e7, dtype={\"cluster_id \": \"int32\", \"patch_id \": \"category\", \\\n",
    "                                                                 \"responses.resp_msg_id\": \"category\", \\\n",
    "                                                                 \"responses.parent\": \"category\", \\\n",
    "                                                                 \"upstream\": \"category\"}).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "final = final.compute(num_workers=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently, duplicates can only be eliminated after converting to pandas. I suspect, while Dask is merging \n",
    "# several distributed dataframes, all duplicates cannot be detected. They are only found when the results \n",
    "# are collected as a whole\n",
    "final.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size considerable reduced than df_dask_final\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe - intermediate denormalized data for the kernel patches with email response \n",
    "# and commit data\n",
    "final.to_csv(\"df_pd_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Responding author from message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_final = pd.read_csv(\"df_pd_final.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no patch and other infos\n",
    "indexNames = df_pd_final[ (df_pd_final['patch_id'] == '_') & (df_pd_final['responses.message'].isna()) & (df_pd_final['upstream'].isna())].index\n",
    "df_pd_final.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from ast import literal_eval\n",
    "\n",
    "def try_literal_eval(s):\n",
    "    try:\n",
    "        return literal_eval(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "def _get_message_field(msg, field):\n",
    "    if not(np.all(pd.isnull(msg))):\n",
    "        return email.message_from_bytes(msg)[field]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dd.from_pandas(df_pd_final, npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only necessary when reading from csv, as list columns got transformed to strings\n",
    "# This can probably be eliminated if we know why message is a list in the first place.\n",
    "# TODO: check get_raws method from PaStA\n",
    "final['responses.message'] = final['responses.message'].map(try_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.reset_index().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check meta\n",
    "final['response_author'] = final['responses.message'].map(lambda x: _get_message_field(x, 'from'), meta=pd.Series([], dtype=object, name='x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique responding authors\n",
    "Number of unique authors who have reviewed/commented on patches submitted for this version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['response_author'].nunique().compute(num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"df_dask_final_responders.csv\", single_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dd.read_csv(\"df_dask_final_responders.csv\", blocksize=50e7, dtype={\"cluster_id \": \"int32\", \"patch_id \": \"category\", \\\n",
    "                                                                 \"responses.resp_msg_id\": \"category\", \\\n",
    "                                                                 \"responses.parent\": \"category\", \\\n",
    "                                                                 \"upstream\": \"category\", \\\n",
    "                                                                 \"response_author\": \"category\"}).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors with most reviewed patch counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_patch_counts_dask = final[['patch_id', 'response_author']].groupby('response_author')['patch_id'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_patch_counts_dask.reset_index().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_patch_counts_dask.nlargest(20).compute(). \\\n",
    "plot(kind='barh', stacked=False, figsize=[10,8], colormap='hsv')\n",
    "plt.title('Top 20 responders by patches reviewed')\n",
    "plt.ylabel('Responding authors')\n",
    "plt.xlabel('Number of patch responses ')\n",
    "plt.tight_layout()\n",
    "plt.savefig('author_top20_patch_counts.png')\n",
    "plt.savefig('author_top20_patch_counts.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upstream commits with patch counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patch_ids(patch_ids):\n",
    "    patch_id_list = list(patch_ids)\n",
    "    try:\n",
    "        patch_id_list.remove('_')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return len(set(patch_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_patch_counts_dask = final[['upstream', 'patch_id']].groupby('upstream')['patch_id'].apply(process_patch_ids, meta=pd.Series([], dtype=int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['patch_id'].nunique().compute(num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['upstream'].nunique().compute(num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_patch_counts_dask.nlargest(20).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = upstream_patch_counts_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up[up == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_patch_counts_dask.nlargest(10).compute(). \\\n",
    "plot(kind='barh', stacked=False, figsize=[10,5], colormap='hsv')\n",
    "plt.title('Top 10 upstreams by number of related patches')\n",
    "plt.ylabel('Upstream commits')\n",
    "plt.xlabel('Number of patches')\n",
    "plt.tight_layout()\n",
    "plt.savefig('upstream_top10_patch_counts.png')\n",
    "plt.savefig('upstream_top10_patch_counts.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = sns.distplot(upstream_patch_counts_dask.compute(), bins=40, kde=False,color='blue',\\\n",
    "vertical=False, kde_kws={\"clip\":(0,40)}, hist_kws={\"range\":(0, 40)})\n",
    "ax.set_yscale('log')\n",
    "plt.title('Upstream Distribution over patches')\n",
    "plt.xlabel('patch count')\n",
    "plt.ylabel('upstream')\n",
    "plt.tight_layout()\n",
    "plt.savefig('upstream_dist_patch_counts_40bins.png')\n",
    "plt.savefig('upstream_dist_patch_counts_40bins.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_patch_counts_dask[upstream_patch_counts_dask == 6].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upstream commits to number of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask = final[['upstream', 'responses.resp_msg_id']].groupby('upstream')['responses.resp_msg_id'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask.nlargest(5).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask.nlargest(15).compute(). \\\n",
    "plot(kind='barh', stacked=False, figsize=[10,6], colormap='Pastel1')\n",
    "plt.title('Top 15 upstream commits by number of responses')\n",
    "plt.ylabel('Upstream commits')\n",
    "plt.xlabel('Number of patches')\n",
    "plt.tight_layout()\n",
    "plt.savefig('upstream_top15_response_counts.png')\n",
    "plt.savefig('upstream_top15_response_counts.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = sns.distplot(upstream_response_counts_dask.compute(), bins=500, kde=False,color='green',\\\n",
    "vertical=False, kde_kws={\"clip\":(0,500)}, hist_kws={\"range\":(0, 500)})\n",
    "ax.set_yscale('log')\n",
    "plt.title('Upstream Distribution over number of responses')\n",
    "plt.xlabel('response count')\n",
    "plt.ylabel('upstream')\n",
    "plt.tight_layout()\n",
    "plt.savefig('upstream_dist_response_counts_500bins.png')\n",
    "plt.savefig('upstream_dist_response_counts_500bins.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask[upstream_response_counts_dask == 60].count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask[upstream_response_counts_dask == 67].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_response_counts_dask[upstream_response_counts_dask == 52].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = sns.distplot(upstream_response_counts_dask.compute(), bins=200, kde=False,color='blue',\\\n",
    "vertical=False, kde_kws={\"clip\":(0,200)}, hist_kws={\"range\":(0,200)})\n",
    "ax.set_yscale('log')\n",
    "plt.title('Upstream Distribution over responses, 200 bins')\n",
    "plt.xlabel('responses')\n",
    "plt.ylabel('upstream count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('upstream_dist_response_counts_200bins.png')\n",
    "plt.savefig('upstream_dist_response_counts_200bins.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('upstream_response_counts-0-200.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patches to responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_id_response_counts_dask = final[['patch_id', 'responses.resp_msg_id']].groupby('patch_id')['responses.resp_msg_id'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = sns.distplot(patch_id_response_counts_dask.compute(), bins=500, kde=False,color='orange',\\\n",
    "vertical=False, kde_kws={\"clip\":(0,500)}, hist_kws={\"range\":(0,500)})\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('response count')\n",
    "plt.ylabel('patches')\n",
    "plt.title('Patch Distribution over number of responses')\n",
    "plt.tight_layout()\n",
    "plt.savefig('patch_dist_response_counts_500bins.png')\n",
    "plt.savefig('patch_dist_response_counts_500bins.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch distribution by responses distinguished by with or without matching upstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patch distribution by responses without matching upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_responses_upstream_df = final[['patch_id', 'upstream', 'responses.resp_msg_id']]\n",
    "patch_response_without_upstream_dask = patch_responses_upstream_df[patch_responses_upstream_df['upstream'].isna() == True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_without_upstream_grouped_dask = patch_response_without_upstream_dask.groupby('patch_id')['responses.resp_msg_id'].agg('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,10))\n",
    "ax = sns.distplot(patch_response_without_upstream_grouped_dask.compute(), kde=False,color='mediumvioletred',\\\n",
    "vertical=False)\n",
    "ax.set_yscale('log')\n",
    "plt.title('Patch (without matching upstream) Distribution over number of responses')\n",
    "plt.xlabel('response count')\n",
    "plt.ylabel('patches')\n",
    "plt.tight_layout()\n",
    "plt.savefig('patch_without_upstream_dist_response_counts.png')\n",
    "plt.savefig('patch_without_upstream_dist_response_counts.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patch distribution by responses with matching upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_with_upstream_dask = patch_responses_upstream_df[patch_responses_upstream_df['upstream'].isna() == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_with_upstream_grouped_dask = patch_response_with_upstream_dask.groupby('patch_id')['responses.resp_msg_id'].agg('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,10))\n",
    "ax = sns.distplot(patch_response_with_upstream_grouped_dask.compute(), kde=False,color='olivedrab',\\\n",
    "vertical=False)\n",
    "ax.set_yscale('log')\n",
    "plt.title('Patch (with matching upstream) Distribution over number of responses')\n",
    "plt.xlabel('response count')\n",
    "plt.ylabel('patches')\n",
    "plt.tight_layout()\n",
    "plt.savefig('patch_with_upstream_dist_response_counts.png')\n",
    "plt.savefig('patch_with_upstream_dist_response_counts.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_with_upstream_grouped_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_with_upstream_grouped_dask[patch_response_with_upstream_grouped_dask > 1000].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_response_with_upstream_grouped_dask[(patch_response_with_upstream_grouped_dask > 500) & (patch_response_with_upstream_grouped_dask < 700)].compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
